{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluctuating Intensities\n",
    "## Read files from OMERO and analyse fluctuations of pixel intensities\n",
    "### Laura Cooper 29/05/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "This notebook assumes the default group for the user in OMERO is Royle-Cooper and that you are connected to the VPN.\n",
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omero.gateway import BlitzGateway\n",
    "import getpass\n",
    "import numpy as np\n",
    "from scipy import fft, ndimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions\n",
    "#### Convert image stack to np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z_stack(img, c=0, t=0):\n",
    "    \"\"\"\n",
    "    Convert OMERO image object to numpy array\n",
    "    Input: img  OMERO image object\n",
    "           c    number of colour channls\n",
    "           t    number of time steps\n",
    "    \"\"\"\n",
    "    zct_list = [(z, c, t) for z in range(img.getSizeZ())] #Set dimensions of image\n",
    "    pixels = img.getPrimaryPixels()\n",
    "    return np.array(list(pixels.getPlanes(zct_list))) #Read in data one plane at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate turbulence statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turb_stats(f, Fs):\n",
    "    \"\"\"\n",
    "    Get turblence statistics for each pixel\n",
    "    Input: f     numpy array of image\n",
    "           Fs    sample frequency\n",
    "    \"\"\"\n",
    "    L=np.shape(f)\n",
    "    # mean velocity over time for every pixel\n",
    "    ind_u_bar=np.mean(f, axis = 0); #mean over time\n",
    "    # Reynolds decomposition to calculate turbulent fluctuations\n",
    "    ind_u_fluct=np.subtract(f,ind_u_bar)\n",
    "    #Turblence Strength\n",
    "    ind_u_rms=np.std(ind_u_fluct, axis = 0) #standard deviation over time\n",
    "    # Frequency spectrum\n",
    "    ind_u_fft=fft.fft(ind_u_fluct, axis = 0) #fast fourier transform in time\n",
    "    P2=abs(ind_u_fft/L[0]) #2 sided spectrum\n",
    "    P1=P2[0:int(L[0]/2)]; #1 sided spectrum\n",
    "    P1[1:len(P1)-1]=2*P1[1:len(P1)-1];\n",
    "    fd=Fs*np.arange(0,L[0]/2,1)/L[0]; #Freqency domain\n",
    "    return ind_u_bar, ind_u_rms, P1, fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have named the variables here as they would be called in a turbulence study (as this is want makes sense to me). To relate them to the current problem:\n",
    "- Mean velocity is mean intensity\n",
    "- Turbulent fluctuations are intensity flucuations\n",
    "- Turblence Strength is the standard deviation of the set of intensity fluctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate tubulence statistics for all images in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fluc_ds(dataset):\n",
    "    \"\"\"\n",
    "    Get mean turblence statistics for each image in dataset\n",
    "    Input: dataset     OMERO dataset object\n",
    "    \"\"\"\n",
    "    # define arrays results\n",
    "    # 16 is the number of images in each data set.\n",
    "    # 15 is half the number of time steps\n",
    "    u_bar = np.zeros(16) #mean velocity\n",
    "    u_rms = np.zeros(16) #turbulence strength\n",
    "    P1_mean = np.zeros([15,16]) #Amplitude of signal\n",
    "    fd_all = np.zeros([15,16]) #Frequency of signal\n",
    "    Iid = np.zeros(16, dtype=int) #Image IDs for referring back to OMERO\n",
    "    i=0;\n",
    "    for image in conn.getObjects('Image', opts={'dataset': dataset}): #loop all images in data set\n",
    "        Iid[i] = image.getId()\n",
    "        f = get_z_stack(image)\n",
    "        ind_u_bar, ind_u_rms, P1, fd = turb_stats(f, 5.6) #Assumes sample frequency same for all images\n",
    "        #Average in space         \n",
    "        u_bar[i]=np.mean(ind_u_bar, axis=(0,1))\n",
    "        u_rms[i] = np.mean(ind_u_rms, axis=(0,1))\n",
    "        P1_mean[:,i]=np.mean(P1,axis=(1,2))\n",
    "        fd_all[:,i]=fd\n",
    "        i=i+1\n",
    "    return Iid, u_bar, u_rms, P1_mean, fd_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "### Connect to OMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = input('Username: ') #Request user to enter OMERO username\n",
    "password = getpass.getpass(prompt='Password: ') #Request user to enter OMERO password\n",
    "conn = BlitzGateway(username, password, host='camdu.warwick.ac.uk', port=4064) #Use details to connect to OMERO server\n",
    "conn.connect() #Returns true when connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get OMERO IDs\n",
    "List the details of the datasets we are interested in from OMERO. We need the IDs to call the images we want to analyse. The output allows us to identify the relevant datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList Datasets: \\n\", \"=\" * 50)\n",
    "datasets = conn.getObjects(\"Dataset\", opts={'owner': 3}) #get all datasets from owner 3 (SR)\n",
    "keys=[] #create empty lists\n",
    "values=[]\n",
    "for obj in datasets:\n",
    "    print(\"\"\"%s%s:%s  Name:\"%s\" (owner=%s)\"\"\" % (\n",
    "        \" \" * 2,\n",
    "        obj.OMERO_CLASS,\n",
    "        obj.getId(),\n",
    "        obj.getName(),\n",
    "        obj.getOwnerOmeName()\n",
    "    ))\n",
    "    keys.append(obj.getName()) #gather dataset names to use in dictionary\n",
    "    values.append(obj.getId()) #gather dataset IDs to use in dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put names and IDs in dictionary to make it easy to call required datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets=dict(zip(keys[:-1], values[:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up dictionarys for results using the same names as the datasets. _Im here means these are the mean results for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageIDs=dict.fromkeys(keys[:-1])\n",
    "Mean_Vel_Im=dict.fromkeys(keys[:-1])\n",
    "TurbStreng_Im=dict.fromkeys(keys[:-1])\n",
    "Amp_Im=dict.fromkeys(keys[:-1])\n",
    "Freq_Im=dict.fromkeys(keys[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset calculate the turbulence statistics for every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Datasets:\n",
    "    ImageIDs[key], Mean_Vel_Im[key], TurbStreng_Im[key], Amp_Im[key], Freq_Im[key] = Fluc_ds(Datasets[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close connection to OMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Every image in stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3,figsize=(20,10))\n",
    "fig.add_subplot(111, frameon=False)\n",
    "for key in Datasets:\n",
    "    axs[int(list(Datasets.keys()).index(key)>=3),list(Datasets.keys()).index(key)%3].plot(Freq_Im[key],Amp_Im[key])\n",
    "    axs[int(list(Datasets.keys()).index(key)>=3),list(Datasets.keys()).index(key)%3].title.set_text(key)\n",
    "\n",
    "# hide tick and tick label of the big axes\n",
    "plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
    "plt.grid(False)\n",
    "plt.xlabel(\"Frequency\",fontsize = 20)\n",
    "plt.ylabel(\"Relative Amplitude\",fontsize = 20)\n",
    "plt.title(\"Frequency Spectra for Individual Images in Datasets\",fontsize = 20,pad=40)\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset, the frequency spectrum of each image is plotted. Note that the y axis are different. INV and recycling endosomes show much higher amplitudes than the other four datasets, i.e. they have larger changes in intensity. I was hoping the graphs would show different peaks. This would indicate that the pixel intensitites were fluctuating a different speeds. To find out, the analysis needs to be run for more time steps.\n",
    "\n",
    "The mean values for each dataset are also found and plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amp_meanDS=dict.fromkeys(keys[:-1])\n",
    "Freq_meanDS=dict.fromkeys(keys[:-1])\n",
    "Amp_stdDS=dict.fromkeys(keys[:-1])\n",
    "Mean_Vel_DS=dict.fromkeys(keys[:-1])\n",
    "TurbStreng_DS=dict.fromkeys(keys[:-1])\n",
    "for key in Amp_meanDS:\n",
    "    Amp_meanDS[key]=np.mean(Amp_Im[key], axis=1)\n",
    "    Freq_meanDS[key]=np.mean(Freq_Im[key], axis=1)\n",
    "    Amp_stdDS[key]=np.std(Amp_Im[key], axis=1)\n",
    "    Mean_Vel_DS[key]=np.mean(Mean_Vel_Im[key])\n",
    "    TurbStreng_DS[key]=np.mean(TurbStreng_Im[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3,figsize=(20,10),sharey=True)\n",
    "fig.add_subplot(111, frameon=False)\n",
    "for key in Datasets:\n",
    "    axs[int(list(Datasets.keys()).index(key)>=3),list(Datasets.keys()).index(key)%3].plot(Freq_meanDS[key],Amp_meanDS[key])\n",
    "    axs[int(list(Datasets.keys()).index(key)>=3),list(Datasets.keys()).index(key)%3].fill_between(Freq_meanDS[key], Amp_meanDS[key]-Amp_stdDS[key], Amp_meanDS[key]+Amp_stdDS[key] ,alpha=0.3)\n",
    "    axs[int(list(Datasets.keys()).index(key)>=3),list(Datasets.keys()).index(key)%3].title.set_text(key)\n",
    "plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
    "plt.grid(False)\n",
    "plt.xlabel(\"Frequency\",fontsize = 20)\n",
    "plt.ylabel(\"Relative Amplitude\",fontsize = 20)\n",
    "plt.title(\"Frequency Spectra for Mean of Datasets\",fontsize = 20,pad=40)\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the mean frequency spectrum of each data set is shown. The y-axes are all the same to emphasis the differences in the amplitude. The shaded area shows $\\pm$ 1 standard deviation from the mean.\n",
    "\n",
    "The mean intensity of the pixels in each image are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "ax.bar(np.arange(len(list(Mean_Vel_DS.values()))), list(Mean_Vel_DS.values()), yerr=list(TurbStreng_DS.values()), align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_ylabel('Mean Pixel Intensity',fontsize=20)\n",
    "ax.set_xticks(np.arange(len(list(Mean_Vel_DS.values()))))\n",
    "ax.set_xticklabels(Mean_Vel_DS.keys(), fontsize=12)\n",
    "ax.set_title('Mean Pixel Intensity of Each Dataset',fontsize=20)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error bars show the $\\pm$ 1 root mean square of the fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
